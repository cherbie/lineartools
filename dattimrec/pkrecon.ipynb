{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PK Date & Time Reconciliation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Google Drive\n",
    "Authorise application access to Google Drive (read & write permission)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"drive/My Drive/Colab Notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import external modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pprint\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Output Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Global_ scope variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfolder = './test/pk/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the __output folder__ in which all output files will be placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(outputfolder):\n",
    "    os.makedirs(outputfolder, 0o755) # owner execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View contents of folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls -l ./test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define output file writing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeFile(filename: str, contents: object):\n",
    "    # Create function to allow for file creation in output.\n",
    "    path = os.path.join(outputfolder, filename)\n",
    "    with open(path, 'w') as outputfile:\n",
    "        outputfile.write(pprint.pformat(contents))\n",
    "\n",
    "def writeJSON(filename: str, contents: object):\n",
    "    # Create function to allow for file creation in output.\n",
    "    path = os.path.join(outputfolder, filename)\n",
    "    with open(path, 'w') as outputfile:\n",
    "        outputfile.write(json.dumps(contents))\n",
    "        \n",
    "def writeErrorCSV(filename: str, contents: object):\n",
    "    path = os.path.join(outputfolder, filename)\n",
    "    with open(path, 'w') as outputfile:\n",
    "        fieldnames = ['subjectid', 'period', 'timepoint', 'sourceDate', 'sourceTime', 'pkDate', 'pkTime', 'message']\n",
    "        writer = csv.DictWriter(outputfile, fieldnames=fieldnames)\n",
    "        writer.writeheader() # place headers in csv file.\n",
    "        for key in contents:\n",
    "            if key == 'errors' or  key  == 'total':\n",
    "                    continue\n",
    "            for data in contents[key]:\n",
    "                # cycle through list of errors\n",
    "                sourcedate = '-'\n",
    "                sourcetime = '-'\n",
    "                pkdate = '-'\n",
    "                pktime = '-'\n",
    "                msg =  ''\n",
    "                if data['date']['error']:\n",
    "                    sourcedate = data['date']['source']\n",
    "                    pkdate = data['date']['pk']\n",
    "                if data['time']['error']:\n",
    "                    sourcetime = data['time']['source']\n",
    "                    pktime = data['time']['pk']\n",
    "                if 'msg' in data:\n",
    "                    msg = data['msg']\n",
    "\n",
    "                row = {\n",
    "                    'subjectid': data['subjectid'],\n",
    "                    'period': data['period'],\n",
    "                    'timepoint': data['timepoint'],\n",
    "                    'sourceDate': sourcedate,\n",
    "                    'sourceTime': sourcetime,\n",
    "                    'pkDate': pkdate,\n",
    "                    'pkTime': pktime,\n",
    "                    'message': msg\n",
    "                }\n",
    "                writer.writerow(row) # write to file\n",
    "    print('CSV write complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Mapping\n",
    "\n",
    "Map csv file records to the csv file records of medrio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randfilename = './test/pk/rand_coh1.csv'\n",
    "\n",
    "subjectMap = dict() # dictionary for randomisation to subject id.\n",
    "\n",
    "randCol = 'DARandNum_C' # column header for randomisation number\n",
    "subjectCol = 'Subject ID' # column header for subject id\n",
    "\n",
    "with open(randfilename) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        subjectMap[f'{row[randCol]}'] = row[subjectCol]\n",
    "\n",
    "writeFile('subjectMapping.txt', subjectMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Configuration File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configfilename = './test/pk/config.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse config file and establish relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configDict = dict()\n",
    "\n",
    "with open(configfilename) as jsonfile:\n",
    "    configDict = json.load(jsonfile)\n",
    "\n",
    "pprint.pp(configDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Medrio Source File\n",
    "\n",
    "Create dictionary mapping for each subject to allow for hash map search of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcefilename = './test/pk/source_coh1.csv'\n",
    "\n",
    "sourceMap = dict() # dictionary for subject data\n",
    "\n",
    "subjectidcol = 'Subject ID'\n",
    "visitCol = 'Visit' # used to find the period\n",
    "\n",
    "# Regular expression objects\n",
    "dateregex = re.compile(r'dat', flags=re.I)\n",
    "timeregex = re.compile(r'tim', flags=re.I)\n",
    "periodRegex = re.compile(r'period.*([0-9])', flags=re.I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Parse the source file and structure data into the __sourceMap__ dictionary variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read File\n",
    "with open(sourcefilename) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        # Get Period of Row\n",
    "        match = periodRegex.search(row.get(visitCol).strip())\n",
    "        if match is None:\n",
    "            print(\"Error: Visit period could not be matched.\")\n",
    "            continue\n",
    "        \n",
    "        if row[subjectidcol] not in sourceMap:\n",
    "            sourceMap[f'{row[subjectidcol]}'] = dict()\n",
    "        if match.group(1) not in sourceMap[f'{row[subjectidcol]}']:\n",
    "            sourceMap[f'{row[subjectidcol]}'][f'{match.group(1)}'] = dict()\n",
    "        \n",
    "        # Record data values\n",
    "        for key in row:\n",
    "            if row[key] == '':\n",
    "                continue\n",
    "            value = None\n",
    "            if dateregex.search(key) is not None:\n",
    "                # Date\n",
    "                value = datetime.datetime.strptime(row.get(key).strip(), '%m/%d/%Y')\n",
    "            elif timeregex.search(key) is not None:\n",
    "                # Time\n",
    "                value = datetime.datetime.strptime(row.get(key).strip(), '%H:%M')\n",
    "            else:\n",
    "                value = row.get(key, '')\n",
    "            \n",
    "            sourceMap[f'{row[subjectidcol]}'][f'{match.group(1)}'][f'{key}'] = value\n",
    "\n",
    "writeFile('medrioData.txt', sourceMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Comparison File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisonMap = dict() # emtpy dictionary\n",
    "\n",
    "comparisonfilename = './test/pk/comparison_1.csv'\n",
    "\n",
    "randomisationCol = 'Subject'\n",
    "periodCol = 'Period'\n",
    "\n",
    "periodRegex = re.compile(r'period.*([0-9])', flags=re.I)\n",
    "\n",
    "scheduleCol = 'Scheduled time (hrs post dose)'\n",
    "dateCol = 'Blood Sample date'\n",
    "timeCol = 'Blood Sample time (24 hrs format)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse comparison file data and structure into the __comparisonMap__ dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read File\n",
    "with open(comparisonfilename) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row[dateCol] == '':\n",
    "            continue # Skip empty rows\n",
    "        \n",
    "        # Interpret Period\n",
    "        match = periodRegex.search(row.get(periodCol,''))\n",
    "        if match is None:\n",
    "            print(\"Error: Visit period could not be matched.\")\n",
    "            continue\n",
    "            \n",
    "        if row[randomisationCol] not in comparisonMap:\n",
    "            comparisonMap[f'{row[randomisationCol]}'] = dict()\n",
    "        if match.group(1) not in comparisonMap[f'{row[randomisationCol]}']:\n",
    "            comparisonMap[f'{row[randomisationCol]}'][f'{match.group(1)}'] = dict()\n",
    "        \n",
    "        # Fetch infomation\n",
    "        info = {\n",
    "            \"timepoint\": row.get(scheduleCol, ''),\n",
    "            \"date\": datetime.datetime.strptime(row.get(dateCol).strip(), '%d-%b-%y'),\n",
    "            \"time\": datetime.datetime.strptime(row.get(timeCol).strip(), '%H:%M:%S')\n",
    "        }\n",
    "        \n",
    "        # Append new information\n",
    "        if info['timepoint'] not in comparisonMap[f'{row[randomisationCol]}'][f'{match.group(1)}']:\n",
    "            comparisonMap[f'{row[randomisationCol]}'][f'{match.group(1)}'][f'{info[\"timepoint\"]}'] = info\n",
    "        elif comparisonMap[f'{row[randomisationCol]}'][f'{match.group(1)}'][f'{info[\"timepoint\"]}']['date'] != info['date']:\n",
    "            # the date in script does not match previously recorded dates\n",
    "            raise Exception(\"ERROR: date for data point is not consistent within file!\")\n",
    "        elif comparisonMap[f'{row[randomisationCol]}'][f'{match.group(1)}'][f'{info[\"timepoint\"]}']['time'] != info['time']:\n",
    "            # the date in script does not match previously recorded dates\n",
    "            raise Exception(\"ERROR: time for data point is not consistent within file!\")\n",
    "\n",
    "writeFile('comparisonData.txt', comparisonMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Data & Assess Equality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare matching data points and flag inequalities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputLog = {\"errors\": 0, \"total\": 0}\n",
    "for subject in comparisonMap:\n",
    "    outputLog[f'{subject}'] = list() # status reporting\n",
    "\n",
    "    # Loop through each subject\n",
    "    id = subjectMap.get(subject, None) # medrio subject id\n",
    "    if id is None:\n",
    "        outputLog[f'{subject}'].append({\n",
    "            \"status\": \"FAILED\",\n",
    "            \"msg\": \"Medrio subject id could not be identified.\"\n",
    "        })\n",
    "        outputLog['errors'] += 1\n",
    "        continue\n",
    "        #raise Exception(f'Could not identify subject: {subject}')\n",
    "    \n",
    "    # Compare data & log any errors\n",
    "    for period in comparisonMap[subject]:\n",
    "        for timepoint in comparisonMap[subject][period]:\n",
    "            lookuptable = configDict['match'][timepoint]\n",
    "            errorObject = dict()\n",
    "            # Cycle through date and time variables to be compared\n",
    "            try:\n",
    "                datecmp = sourceMap[f'{id}'][period][f'{lookuptable[\"date\"]}'].date() == comparisonMap[subject][period][timepoint]['date'].date()\n",
    "                timecmp = sourceMap[f'{id}'][period][f'{lookuptable[\"time\"]}'].time() == comparisonMap[subject][period][timepoint]['time'].time()\n",
    "            except KeyError as e:\n",
    "                errorObject = {\n",
    "                    \"error\": True,\n",
    "                    'msg': \"Warning: variable most likely not defined for subject in source.\",\n",
    "                }\n",
    "            except:\n",
    "                print('Unknown Error Occured.')\n",
    "                errorObject = {\n",
    "                    \"error\": True,\n",
    "                    'msg': \"Unknown error occured\",\n",
    "                }\n",
    "            \n",
    "            dateError = {'error': False}\n",
    "            timeError = {'error': False}\n",
    "            outputLog['total'] += 1 # increment number of variables assessed\n",
    "            \n",
    "            if not datecmp:\n",
    "                dateError = {\n",
    "                        \"variable\": lookuptable['date'],\n",
    "                        \"source\": sourceMap[f'{id}'][period][f'{lookuptable[\"date\"]}'].date().isoformat(),\n",
    "                        \"pk\": comparisonMap[subject][period][timepoint]['date'].date().isoformat(),\n",
    "                        \"error\": True\n",
    "                    }\n",
    "            if not timecmp:\n",
    "                timeError = {\n",
    "                        \"variable\": lookuptable['time'],\n",
    "                        \"source\": sourceMap[f'{id}'][period][f'{lookuptable[\"time\"]}'].time().isoformat(),\n",
    "                        \"pk\": comparisonMap[subject][period][timepoint]['time'].time().isoformat(),\n",
    "                        \"error\": True\n",
    "                    }\n",
    "            if not datecmp or not timecmp or errorObject.get('error', False):\n",
    "                outputLog['errors'] += 1\n",
    "                outputLog[f'{subject}'].append({\n",
    "                    **errorObject, \n",
    "                    'period': f'Period {period}',\n",
    "                    'timepoint': timepoint,\n",
    "                    'subjectid': id,\n",
    "                    'date': dateError,\n",
    "                    'time': timeError,\n",
    "                })\n",
    "\n",
    "            \n",
    "writeJSON('output.json', outputLog)\n",
    "writeFile('output.txt', outputLog)\n",
    "writeErrorCSV('output.csv', outputLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.pie([outputLog['errors'], outputLog['total']], labels=[outputLog['errors'], outputLog['total']], colors=['#f42613', '#47f747'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
