{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safety Bloods Date & Time Reconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pprint\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Output Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Global_ scope variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfolder = './test/safety/output/coh2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the __output folder__ in which all output files will be placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(outputfolder):\n",
    "    os.makedirs(outputfolder, 0o755) # owner execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View contents of folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxr-xr-x   9 herbsca  staff  288 17 Apr 11:48 \u001b[34mpk\u001b[m\u001b[m/\n",
      "drwxr-xr-x  10 herbsca  staff  320 20 Apr 12:22 \u001b[34msafety\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "%ls -l ./test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define output file writing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeFile(filename: str, contents: object):\n",
    "    # Create function to allow for file creation in output.\n",
    "    path = os.path.join(outputfolder, filename)\n",
    "    with open(path, 'w') as outputfile:\n",
    "        outputfile.write(pprint.pformat(contents))\n",
    "    print('Text file write complete.')\n",
    "\n",
    "def writeJSON(filename: str, contents: object):\n",
    "    # Create function to allow for file creation in output.\n",
    "    path = os.path.join(outputfolder, filename)\n",
    "    with open(path, 'w') as outputfile:\n",
    "        outputfile.write(json.dumps(contents))\n",
    "    print('JSON file write complete.')\n",
    "\n",
    "def writeErrorCSV(filename: str, contents: object):\n",
    "    path = os.path.join(outputfolder, filename)\n",
    "    with open(path, 'w') as outputfile:\n",
    "        fieldnames = ['subjectid', 'type', 'collection', 'visit', 'panel', 'sourceDate', 'sourceTime', 'comparisonDate', 'comparisonTime', 'message']\n",
    "        writer = csv.DictWriter(outputfile, fieldnames=fieldnames)\n",
    "        writer.writeheader() # place headers in csv file.\n",
    "        for key in contents:\n",
    "            if key == 'errors' or  key  == 'total':\n",
    "                    continue\n",
    "            for data in contents[key]:\n",
    "                # cycle through list of errors\n",
    "                sourcedate = '-'\n",
    "                sourcetime = '-'\n",
    "                comparisondate = '-'\n",
    "                comparisontime = '-'\n",
    "                msg =  ''\n",
    "                if 'date' in data and data['date']['error']:\n",
    "                    sourcedate = data['date']['source']\n",
    "                    comparisondate = data['date']['comparison']\n",
    "                if 'time' in data and data['time']['error']:\n",
    "                    sourcetime = data['time']['source']\n",
    "                    comparisontime = data['time']['comparison']\n",
    "                if 'msg' in data:\n",
    "                    msg = data['msg']\n",
    "\n",
    "                row = {\n",
    "                    'subjectid': data['subject'],\n",
    "                    'visit': data['visit'],\n",
    "                    'type': data['type'],\n",
    "                    'collection': data['collection'],\n",
    "                    'panel': data['panel'],\n",
    "                    'sourceDate': sourcedate,\n",
    "                    'sourceTime': sourcetime,\n",
    "                    'comparisonDate': comparisondate,\n",
    "                    'comparisonTime': comparisontime,\n",
    "                    'message': msg\n",
    "                }\n",
    "                writer.writerow(row) # write to file\n",
    "    print('CSV file write complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Configuration File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse config file and establish relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'match': {'visit': {'Screening': 0,\n",
      "                     'Period 1 Day-2': 1,\n",
      "                     'Period 1 Day 2': 2,\n",
      "                     'Period 2 Day 2': 4,\n",
      "                     'Period 2 Day-2': 3,\n",
      "                     'Period 2 Day 7/EOS': 5,\n",
      "                     'Unscheduled': 6,\n",
      "                     'Day -2 [Period 1]': 1,\n",
      "                     'Day 2 [Period 1]': 2,\n",
      "                     'Day -2 [Period 2]': 3,\n",
      "                     'Day 2 [Period 2]': 4,\n",
      "                     'Day 7 [Period 2] EOS': 5,\n",
      "                     '_array': ['Screening',\n",
      "                                'Period 1 Day-2',\n",
      "                                'Period 1 Day 2',\n",
      "                                'Period 2 Day-2',\n",
      "                                'Period 2 Day 2',\n",
      "                                'Period 2 Day 7/EOS',\n",
      "                                'Unscheduled']}}}\n"
     ]
    }
   ],
   "source": [
    "# [TODO] - Specify the file path to the config json file\n",
    "config_filename = './test/safety/config.json'\n",
    "\n",
    "configDict = dict()\n",
    "\n",
    "with open(config_filename) as jsonfile:\n",
    "    configDict = json.load(jsonfile)\n",
    "\n",
    "pprint.pp(configDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Medrio Source File\n",
    "\n",
    "Create dictionary mapping for each subject to allow for hash map search of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] - Specify the file path to the source .csv file\n",
    "source_filename = './test/safety/source.csv'\n",
    "\n",
    "# [TODO] - Specify the exact string column header for the subject id's\n",
    "subjectidcol: str  = 'Subject ID'\n",
    "# [TODO] - Specify the exact string column header for the visit name column\n",
    "visitCol: str = 'Visit'\n",
    "\n",
    "# REGULAR EXPRESSION OBJECTS\n",
    "# [TODO] - Regex pattern to identify a date-time variable / data point\n",
    "datetimeregex = re.compile(r'dattim', flags=re.I)\n",
    "# [TODO] - Regex pattern to identify a Coagulation collection variable\n",
    "coagregex = re.compile(r'coag', flags=re.I)\n",
    "# [TODO] - Regex pattern to identify Chemistry collection variable\n",
    "chemregex = re.compile(r'chem', flags=re.I)\n",
    "# [TODO] - Regex pattern to identify Glucose collection variable\n",
    "glucregex = re.compile(r'gluc', flags=re.I)\n",
    "# [TODO] - Regex pattern to identify Serology collection variable\n",
    "serregex = re.compile(r'ser', flags=re.I)\n",
    "# [TODO] - Regex pattern to identify Haematology collection variable\n",
    "haemregex = re.compile(r'haem', flags=re.I)\n",
    "# [TODO] - Regex pattern to identify Urine collection variable\n",
    "urineregex = re.compile(r'UC')\n",
    "# [TODO] - Regex pattern to identify Comments collection variables\n",
    "commregex = re.compile(r'comm', flags=re.I)\n",
    "\n",
    "# ... insert more as necessary and attempt to add in the code in the following cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the source file and structure data into the __sourceMap__ dictionary variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file write complete.\n"
     ]
    }
   ],
   "source": [
    "sourceMap = dict() # DICTIONARY FOR SUBJECT DATA\n",
    "\n",
    "# READ THE SOURCE FILE\n",
    "with open(source_filename) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        # GET THE VISIT FOR THE ROW OF DATA\n",
    "        try:\n",
    "            visitid = configDict['match']['visit'][f'{row[visitCol]}']\n",
    "        except:\n",
    "            print(f'Error: Visit could not be matched from configuration file: {row[visitCol]}')\n",
    "            continue\n",
    "        \n",
    "        # CREATE DICITONARY OBJECTS IF THEY DO NOT EXIST\n",
    "        if row[subjectidcol] not in sourceMap:\n",
    "            sourceMap[f'{row[subjectidcol]}'] = dict()\n",
    "        if visitid not in sourceMap[f'{row[subjectidcol]}']:\n",
    "            sourceMap[f'{row[subjectidcol]}'][visitid] = dict()\n",
    "        \n",
    "        # CYCLE THROUGH COLUMNS AND RECORD DATA VALUES\n",
    "        for key in row:\n",
    "            t = '' # TREAT AS THE \"TYPE\" VARIABLE\n",
    "            if row[key] == '':\n",
    "                continue # SKIP EMPTY CELLS\n",
    "            value = dict()\n",
    "            \n",
    "            # SEARCH FOR URINE DATA POINT MATCH\n",
    "            if urineregex.search(key) is not None:\n",
    "                t = 'urine'\n",
    "                if t not in sourceMap[f'{row[subjectidcol]}'][visitid]:\n",
    "                    sourceMap[f'{row[subjectidcol]}'][visitid][f'{t}'] = dict()\n",
    "                \n",
    "                if datetimeregex.search(key) is not None:\n",
    "                    # DATE AND TIME\n",
    "                    valueError = False\n",
    "                    try:\n",
    "                        value = {'datetime': datetime.datetime.strptime(row.get(key).strip(), '%m/%d/%y %H:%M')} # EXTRACT & FORMAT DATE-TIME VARIABLE IN A CERTAIN WAY\n",
    "                    except ValueError:\n",
    "                        valueError = True\n",
    "                    if valueError:\n",
    "                        # try another date & time format\n",
    "                        value = {'datetime': datetime.datetime.strptime(row.get(key).strip(), '%m/%d/%Y %H:%M')} # EXTRACT & FORMAT DATE-TIME VARIABLE IN A CERTAIN WAY\n",
    "                else:\n",
    "                    value = {'urine': row.get(key, 'No')} # RECORD IF URINE WAS COLLECTED OR NOT\n",
    "            \n",
    "            # SEARCH FOR BLOOD COLLECTION MATCH\n",
    "            else:\n",
    "                t = 'blood'\n",
    "                if t not in sourceMap[f'{row[subjectidcol]}'][visitid]:\n",
    "                    sourceMap[f'{row[subjectidcol]}'][visitid][f'{t}'] = dict()\n",
    "                \n",
    "                if datetimeregex.search(key) is not None:\n",
    "                    valueError = False\n",
    "                    try:\n",
    "                        value = {'datetime': datetime.datetime.strptime(row.get(key).strip(), '%m/%d/%y %H:%M')} # EXTRACT & FORMAT DATE-TIME VARIABLE IN A CERTAIN WAY\n",
    "                    except ValueError:\n",
    "                        valueError = True\n",
    "                    if valueError:\n",
    "                        # try another date & time format\n",
    "                        value = {'datetime': datetime.datetime.strptime(row.get(key).strip(), '%m/%d/%Y %H:%M')} # EXTRACT & FORMAT DATE-TIME VARIABLE IN A CERTAIN WAY\n",
    "                    k = 'datetime'\n",
    "                    \n",
    "                # NOTE IF THE CERTAIN BLOODS WERE COLLECTED ? OR NOT ?\n",
    "                elif coagregex.search(key) is not None:\n",
    "                    k = 'coag'\n",
    "                    value = {'coag': row.get(key, 'No')}\n",
    "                elif chemregex.search(key) is not None:\n",
    "                    k = 'chem'\n",
    "                    value = {'chem': row.get(key, 'No')}\n",
    "                elif glucregex.search(key) is not None:\n",
    "                    k = 'gluc'\n",
    "                    value = {'gluc': row.get(key, 'No')}\n",
    "                elif serregex.search(key) is not None:\n",
    "                    k = 'ser'\n",
    "                    value = {'ser': row.get(key, 'No')}\n",
    "                elif haemregex.search(key) is not None:\n",
    "                    k = 'haem'\n",
    "                    value = {'haem': row.get(key, 'No')}\n",
    "                elif commregex.search(key) is not None:\n",
    "                    k = 'comm'\n",
    "                    value = {'comm': row.get(key, '')}\n",
    "                else:\n",
    "                    k = key\n",
    "                    value = {'other': row.get(key, '')}\n",
    "            \n",
    "            sourceMap[f'{row[subjectidcol]}'][visitid][f'{t}'].update({**value}) # ADD THE ACCUMULATED VALUE TO THE SOURCE MAP\n",
    "\n",
    "writeFile('sourceData.txt', sourceMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Comparison File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] - Specify the file path to the comparison .csv file\n",
    "comparison_filename = './test/safety/comparison_coh1&2.csv'\n",
    "\n",
    "# REGULAR EXPRESSION OBJECTS\n",
    "# [TODO] - Regex pattern to identify a date-time variable / data point\n",
    "datetimeregex = re.compile(r'dattim', flags=re.I)\n",
    "# [TODO] - Regex pattern to identify a Coagulation collection variable\n",
    "coagregex = re.compile(r'coag', flags=re.I)\n",
    "# [TODO] - Regex pattern to identify Chemistry collection variable\n",
    "chemregex = re.compile(r'chem', flags=re.I)\n",
    "# [TODO] - Regex pattern to identify Glucose collection variable\n",
    "# Note: Only compared / searched for if \"TestPanel\" is left bank in the comparison file\n",
    "glucregex = re.compile(r'gluc', flags=re.I)\n",
    "# [TODO] - Regex pattern to identify Serology collection variable\n",
    "serregex = re.compile(r'ser', flags=re.I)\n",
    "# [TODO] - Regex pattern to identify Haematology collection variable\n",
    "haemregex = re.compile(r'haem', flags=re.I)\n",
    "# [TODO] - Regex pattern to identify Urine collection variable\n",
    "urineregex = re.compile(r'ur', flags=re.I)\n",
    "# [TODO] - Regex pattern to identify Comments collection variables\n",
    "commregex = re.compile(r'comm', flags=re.I)\n",
    "\n",
    "# [TODO] = Specify the exact column headers for these data points\n",
    "subjectCol1 = 'PatientID1'\n",
    "subjectCol2 = 'PatientID2'\n",
    "dateCol = 'CollDate'\n",
    "timeCol = 'CollTime'\n",
    "visitCol = 'Visit'\n",
    "panelCol = 'TestPanel'\n",
    "nameCol = 'ResultName'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse comparison file data and structure into the __comparisonMap__ dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file write complete.\n"
     ]
    }
   ],
   "source": [
    "comparisonMap = dict() # EMPTY DICTIONARY\n",
    "\n",
    "# READ COMPARISON FILE\n",
    "with open(comparison_filename) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row[dateCol] == '':\n",
    "            continue # SKIP EMPTY ROWS\n",
    "        \n",
    "        # INTERPRET VISIT\n",
    "        try:\n",
    "            visitid = configDict['match']['visit'][f'{row[visitCol]}']\n",
    "        except:\n",
    "            print(f'Error: Visit could not be matched from configuration file: {row[visitCol]}')\n",
    "            continue\n",
    "        \n",
    "        subject = f'{row[subjectCol1]}' # GET THE SUBJECT ID (MEDRIO)\n",
    "        \n",
    "        if visitid == 6:\n",
    "            continue # SKIP UNSCHEDULED VISIT\n",
    "            \n",
    "        # ADD DICTIONARY TO SOURCE MAP IF IT DOESN'T ALREADY EXIST\n",
    "        if subject not in comparisonMap:\n",
    "            comparisonMap[subject] = dict()\n",
    "        if visitid not in comparisonMap[subject]:\n",
    "            comparisonMap[subject][visitid] = dict()\n",
    "        \n",
    "        # FETCH INFORMATION IN ROW\n",
    "        info = dict()\n",
    "        \n",
    "        # TIME & DATE COLLECTION INFORMATION\n",
    "        timeval = {\n",
    "            'date': datetime.datetime.strptime(row.get(dateCol).strip(), '%d/%m/%y'), # [TODO] - CHANGE FORMAT OF DATE VALUE READ - EXTRACT DATA VALUE AND PARSE BASED ON SPECIFIED FORMAT\n",
    "            'time': datetime.datetime.strptime(row.get(timeCol).strip(), '%H:%M:%S') # [TODO] - CHANGE THE FORMAT OF THE TIME VALUE READ\n",
    "        }\n",
    "        \n",
    "        k = None # TEST NAME\n",
    "        \n",
    "        # MATCH THE TEST PANEL TO A PARTICULAR DATA POINT COLLECTION\n",
    "        if coagregex.search(row[panelCol]) is not None:\n",
    "            k = 'coag'\n",
    "            info[k] = {**timeval}\n",
    "        elif chemregex.search(row[panelCol]) is not None:\n",
    "            k = 'chem'\n",
    "            info[k] = {**timeval}\n",
    "        elif serregex.search(row[panelCol]) is not None:\n",
    "            k = 'ser'\n",
    "            info[k] = {**timeval}\n",
    "        elif haemregex.search(row[panelCol]) is not None:\n",
    "            k = 'haem'\n",
    "            info[k] = {**timeval}\n",
    "        elif urineregex.search(row[panelCol]) is not None:\n",
    "            k = 'urine'\n",
    "            info[k] = {**timeval}\n",
    "        elif row[panelCol] == '':\n",
    "            if glucregex.search(row[nameCol]) is not None:\n",
    "                k = 'gluc'\n",
    "                info[k] = {**timeval}\n",
    "            else:\n",
    "                continue # NOT INTERESTED - UNKNOWN COLLECTION\n",
    "        else:\n",
    "            continue # NOT INTERESTED - UNKNOWN COLLECTION\n",
    "        \n",
    "        # APPEND NEW INFORMATION ABOUT TEST PANEL IF NOT ALREADY DEFINED\n",
    "        if k not in comparisonMap[subject][visitid]:\n",
    "            comparisonMap[subject][visitid].update({**info}) # REMEMBER VALUES\n",
    "        \n",
    "        # SEE IF DATE IN COMPARISON FILE MATCHES PREVIOUSLY RECORDED DATE\n",
    "        elif comparisonMap[subject][visitid][k]['date'] != info[k]['date']:\n",
    "            # the date in the script does not match previously recorded dates\n",
    "            error = {\n",
    "                'subject': subject,\n",
    "                'visit': row[visitCol],\n",
    "                **info\n",
    "            }\n",
    "            pprint.pp(error)\n",
    "            pprint.pp(comparisonMap[subject][visitid])\n",
    "            raise Exception(\"ERROR: date for data point is not consistent within file!\")\n",
    "        \n",
    "        # SEE IF TIME IN COMPARISON FILE MATCHES PREVIOUSLY RECORDED TIME\n",
    "        elif comparisonMap[subject][visitid][k]['time'] != info[k]['time']:\n",
    "            # the time in the script does not match previously recorded dates\n",
    "            error = {\n",
    "                'subject': subject,\n",
    "                'visit': row[visitCol],\n",
    "                **info\n",
    "            }\n",
    "            pprint.pp(error)\n",
    "            pprint.pp(comparisonMap[subject][visitid])\n",
    "            raise Exception(\"ERROR: time for data point is not consistent within file!\")\n",
    "        else:\n",
    "            # APPEND INFORMATION ( MOST LIKELY JUST THE DATE AND TIME FOR THE ROW / TIMEPOINT)\n",
    "            comparisonMap[subject][visitid].update(info)            \n",
    "\n",
    "writeFile('comparisonData.txt', comparisonMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Data & Assess Equality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare matching data points and flag inequalities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S006-([0-9]){5} not in source.\n",
      "S011-([0-9]){5} not in source.\n",
      "S003-([0-9]){5} not in source.\n",
      "S004-([0-9]){5} not in source.\n",
      "S005-([0-9]){5} not in source.\n",
      "S023-([0-9]){5} not in source.\n",
      "S018-([0-9]){5} not in source.\n",
      "S002-([0-9]){5} not in source.\n",
      "S022-([0-9]){5} not in source.\n",
      "S017-([0-9]){5} not in source.\n",
      "S026-([0-9]){5} not in source.\n",
      "S028-([0-9]){5} not in source.\n",
      "S031-([0-9]){5} not in source.\n",
      "S078-([0-9]){5} not in source.\n",
      "S068-([0-9]){5} not in source.\n",
      "S076-([0-9]){5} not in source.\n",
      "S029-([0-9]){5} not in source.\n",
      "S057-([0-9]){5} not in source.\n",
      "S050-([0-9]){5} not in source.\n",
      "S067-([0-9]){5} not in source.\n",
      "S065-([0-9]){5} not in source.\n",
      "S062-([0-9]){5} not in source.\n",
      "S032-([0-9]){5} not in source.\n",
      "S056-([0-9]){5} not in source.\n",
      "S061-([0-9]){5} not in source.\n",
      "S071-([0-9]){5} not in source.\n",
      "S045-([0-9]){5} not in source.\n",
      "S034-([0-9]){5} not in source.\n",
      "S049-([0-9]){5} not in source.\n",
      "S052-([0-9]){5} not in source.\n",
      "S037-([0-9]){5} not in source.\n",
      "S047-([0-9]){5} not in source.\n",
      "S075-([0-9]){5} not in source.\n",
      "JSON file write complete.\n",
      "Text file write complete.\n",
      "CSV file write complete.\n"
     ]
    }
   ],
   "source": [
    "outputLog = {\"errors\": 0, \"total\": 0}\n",
    "\n",
    "# [TODO] - Specify the regex pattern to indentify urine data in blood samples\n",
    "urineregex = re.compile(r'urine', flags=re.I)\n",
    "\n",
    "subjectKeys = sourceMap.keys().__str__() # ALLOWS FOR EXTRACTION OF MEDRIO SUBJECT ID's\n",
    "\n",
    "# CYCLE THROUGH EACH SUBJECT IN THE COMPARISON FILE\n",
    "for s in comparisonMap:\n",
    "    \n",
    "    # REGEX PATTERN TO MATCH THE SUBJECT ID BY INSERTING THE SCREENING NUMBER -> \"s\"\n",
    "    pattern = f'{s}-([0-9]){{5}}'\n",
    "    match = re.search(pattern, subjectKeys) # FIND MEDRIO SUBJECT ID USING THE SCREENING NUMBER\n",
    "    if match is None:\n",
    "        print(f'{pattern} not in source.')\n",
    "        continue # SUBJECT ID NOT IN SOURCE\n",
    "    \n",
    "    subject = match.group(0) # MATCHED RANDOMISATION NUMBER\n",
    "    \n",
    "    # STATUS REPORTING ON RANDOMISED SUBJECT\n",
    "    outputLog[f'{subject}'] = list()\n",
    "\n",
    "    # COMPARE DATA AND LOG ANY OUTLIERS / ERRORS\n",
    "    # CYCLE THROUGH EACH VISIT IN THE COMPARISON FILE\n",
    "    for visitid in comparisonMap[s]:\n",
    "        # CYCLE THROUGH EACH TEST IN THE COMPARISON FILE\n",
    "        for panel in comparisonMap[s][visitid]:\n",
    "            # EXTRACT VISIT NAME USING INDEX INTO \"_array\" IN THE CONFIG FILE\n",
    "            visitName = configDict['match']['visit']['_array'][visitid]\n",
    "            \n",
    "            # INITIAL VALUES\n",
    "            errorObject = dict()\n",
    "            datecmp = False\n",
    "            timecmp = False\n",
    "            t = '' # TYPE OF SAFETY COLLECTION (BLOOD OR URINE)\n",
    "            \n",
    "            # DETERMINE IF PANEL IS A URINE COLLECTION PANEL\n",
    "            if urineregex.match(panel) is not None:\n",
    "                t = 'urine'\n",
    "            else:\n",
    "                t = 'blood'\n",
    "            \n",
    "            # CYCLE THROUGH DATE AND TIME VARIABLES TO BE COMPARED\n",
    "            try:\n",
    "                if visitid not in sourceMap[subject]:\n",
    "                    raise Exception(f'Visit not defined for the subject in source: {visitName}')\n",
    "                if sourceMap[subject][visitid][t].get(panel, None) is not None and sourceMap[subject][visitid][t].get(panel, '') == 'Yes':\n",
    "                    datecmp = sourceMap[subject][visitid][t]['datetime'].date() == comparisonMap[s][visitid][panel]['date'].date() # COMPARE SOURCE & COMPARISON DATE VALUES\n",
    "                    timecmp = sourceMap[subject][visitid][t]['datetime'].time() == comparisonMap[s][visitid][panel]['time'].time() # COMPARE SOURCE & COMPARISON TIME VALUES\n",
    "                else:\n",
    "                    raise Exception('Test panel is not registed in the source data')\n",
    "\n",
    "                if not datecmp:\n",
    "                    # DATE VALUES ARE NOT EQUIVALENT\n",
    "                    dateError = {\n",
    "                            \"source\": sourceMap[subject][visitid][t]['datetime'].date().isoformat(),\n",
    "                            \"comparison\": comparisonMap[s][visitid][panel]['date'].date().isoformat(),\n",
    "                            \"error\": True\n",
    "                        }\n",
    "                    errorObject = {\n",
    "                        \"error\": True,\n",
    "                        \"type\": \"ERROR\",\n",
    "                        \"date\": dateError\n",
    "                    }\n",
    "\n",
    "                if not timecmp:\n",
    "                    # TIME VALUES ARE NOT EQUIVALENT\n",
    "                    timeError = {\n",
    "                            \"source\": sourceMap[subject][visitid][t]['datetime'].time().isoformat(),\n",
    "                            \"comparison\": comparisonMap[s][visitid][panel]['time'].time().isoformat(),\n",
    "                            \"error\": True\n",
    "                        }\n",
    "                    errorObject = {\n",
    "                        \"error\": True,\n",
    "                        \"type\": \"ERROR\",\n",
    "                        \"time\": timeError\n",
    "                    }\n",
    "                if 'comm' in sourceMap[subject][visitid][t]:\n",
    "                    # COMMENTS WHERE RECORDED HENCE JUST FLAG THEM FOR CHECKING\n",
    "                    errorObject = {\n",
    "                        \"error\": True,\n",
    "                        \"type\": \"WARNING\",\n",
    "                        \"msg\": sourceMap[subject][visitid][t]['comm'],\n",
    "                        \"date\": {\n",
    "                            \"source\": sourceMap[subject][visitid][t]['datetime'].date().isoformat(),\n",
    "                            \"comparison\": comparisonMap[s][visitid][panel]['date'].date().isoformat(),\n",
    "                            \"error\": True\n",
    "                        },\n",
    "                        \"time\": {\n",
    "                            \"source\": sourceMap[subject][visitid][t]['datetime'].time().isoformat(),\n",
    "                            \"comparison\": comparisonMap[s][visitid][panel]['time'].time().isoformat(),\n",
    "                            \"error\": True\n",
    "                        }\n",
    "                    }\n",
    "            \n",
    "            # LOG ANY ERRORS TO THE ERROR FILE\n",
    "            except KeyError as e:\n",
    "                print(e)\n",
    "                errorObject = {\n",
    "                    \"type\": \"WARNING\",\n",
    "                    \"error\": True,\n",
    "                    'msg': \"Warning: variable most likely not defined for subject in source.\"\n",
    "                }\n",
    "            except Exception as e:\n",
    "                errorObject = {\n",
    "                        \"error\": True,\n",
    "                        \"type\": \"WARNING\",\n",
    "                        \"msg\": f'{e}',\n",
    "                        \"panel\": panel,\n",
    "                        \"visit\": visitName,\n",
    "                    }\n",
    "            except:\n",
    "                print('Unknown Error Occured.')\n",
    "                errorObject = {\n",
    "                    \"error\": True,\n",
    "                    \"type\": \"ERROR\",\n",
    "                    'msg': \"Unknown error occured\",\n",
    "                }\n",
    "            finally:\n",
    "                if errorObject.get('error', False):\n",
    "                    outputLog['errors'] += 1\n",
    "                    outputLog[f'{subject}'].append({\n",
    "                        **errorObject,\n",
    "                        'visit': visitName,\n",
    "                        'panel': panel,\n",
    "                        'subject': subject,\n",
    "                        'collection': t\n",
    "                    })\n",
    "                outputLog['total'] += 1 # INCREMENT NUMBER OF VARIABLES ASSESSED\n",
    "\n",
    "# WRITE DICTINARY TO FILES\n",
    "writeJSON('output.json', outputLog)\n",
    "writeFile('output.txt', outputLog)\n",
    "writeErrorCSV('output.csv', outputLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.patches.Wedge at 0x11a694a90>,\n",
       "  <matplotlib.patches.Wedge at 0x11a694f40>],\n",
       " [Text(1.0904192696283328, 0.1448648212065772, '28'),\n",
       "  Text(-1.0904192577605085, -0.1448649105374441, '638')])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.pie([outputLog['errors'], outputLog['total']], labels=[outputLog['errors'], outputLog['total']], colors=['#f42613', '#47f747'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
