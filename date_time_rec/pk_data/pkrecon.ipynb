{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PK Date & Time Reconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pprint\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Output Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Global_ scope variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfolder = './test/pk/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the __output folder__ in which all output files will be placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(outputfolder):\n",
    "    os.makedirs(outputfolder, 0o755) # owner execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View contents of folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxr-xr-x  9 herbsca  staff  288 17 Apr 11:48 \u001b[34mpk\u001b[m\u001b[m/\n",
      "drwxr-xr-x  3 herbsca  staff   96 17 Apr 11:20 \u001b[34msafety\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "%ls -l ./test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define output file writing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeFile(filename: str, contents: object):\n",
    "    # Create function to allow for file creation in output.\n",
    "    path = os.path.join(outputfolder, filename)\n",
    "    with open(path, 'w') as outputfile:\n",
    "        outputfile.write(pprint.pformat(contents))\n",
    "\n",
    "def writeJSON(filename: str, contents: object):\n",
    "    # Create function to allow for file creation in output.\n",
    "    path = os.path.join(outputfolder, filename)\n",
    "    with open(path, 'w') as outputfile:\n",
    "        outputfile.write(json.dumps(contents))\n",
    "        \n",
    "def writeErrorCSV(filename: str, contents: object):\n",
    "    path = os.path.join(outputfolder, filename)\n",
    "    with open(path, 'w') as outputfile:\n",
    "        fieldnames = ['subjectid', 'period', 'timepoint', 'sourceDate', 'sourceTime', 'pkDate', 'pkTime', 'message']\n",
    "        writer = csv.DictWriter(outputfile, fieldnames=fieldnames)\n",
    "        writer.writeheader() # place headers in csv file.\n",
    "        for key in contents:\n",
    "            if key == 'errors' or  key  == 'total':\n",
    "                    continue\n",
    "            for data in contents[key]:\n",
    "                # cycle through list of errors\n",
    "                sourcedate = '-'\n",
    "                sourcetime = '-'\n",
    "                pkdate = '-'\n",
    "                pktime = '-'\n",
    "                msg =  ''\n",
    "                if data['date']['error']:\n",
    "                    sourcedate = data['date']['source']\n",
    "                    pkdate = data['date']['pk']\n",
    "                if data['time']['error']:\n",
    "                    sourcetime = data['time']['source']\n",
    "                    pktime = data['time']['pk']\n",
    "                if 'msg' in data:\n",
    "                    msg = data['msg']\n",
    "\n",
    "                row = {\n",
    "                    'subjectid': data['subjectid'],\n",
    "                    'period': data['period'],\n",
    "                    'timepoint': data['timepoint'],\n",
    "                    'sourceDate': sourcedate,\n",
    "                    'sourceTime': sourcetime,\n",
    "                    'pkDate': pkdate,\n",
    "                    'pkTime': pktime,\n",
    "                    'message': msg\n",
    "                }\n",
    "                writer.writerow(row) # write to file\n",
    "    print('CSV write complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Mapping\n",
    "\n",
    "Map csv file records to the csv file records of medrio using the randomisation number. This _ipython_ cell attempts to avoid the user manually having to specify the mapping of each subject to data, instead just provide a file that maps a certain __Subject ID__ to a certain __Randomisation Number__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './test/pk/rand_coh1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f871b5620c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Read the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_filename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './test/pk/rand_coh1.csv'"
     ]
    }
   ],
   "source": [
    "# [TODO] Define the file path to the randomisation number to subject-id mapping\n",
    "rand_filename: str = './test/pk/rand_coh1.csv'\n",
    "\n",
    "subjectMap = dict() # dictionary for randomisation to subject id.\n",
    "\n",
    "# [TODO] - Column header for randomisation number\n",
    "randCol = 'DARandNum_C'\n",
    "\n",
    "# [TODO] - Column header for subject id\n",
    "subjectCol = 'Subject ID' \n",
    "\n",
    "# Read the file\n",
    "with open(rand_filename) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        subjectMap[f'{row[randCol]}'] = row[subjectCol]\n",
    "\n",
    "writeFile('subjectMapping.txt', subjectMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Configuration File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse config file and establish relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': {'file': './INPUT.csv'},\n",
      " 'comparison': {'file': './COMPARISON.csv'},\n",
      " 'output': {'directory': './output'},\n",
      " 'match': {'0': {'date': 'PKPDDat_C', 'time': 'PKPDTim_C'},\n",
      "           '0.25': {'date': 'PK15Dat_C', 'time': 'PK15Tim_C'},\n",
      "           '0.5': {'date': 'PK30Dat_C', 'time': 'PK30Tim_C'},\n",
      "           '1': {'date': 'PK1Dat_C', 'time': 'PK1Tim_C'},\n",
      "           '1.5': {'date': 'PK90Dat_C', 'time': 'PK90Tim_C'},\n",
      "           '2': {'date': 'PK2Dat_C', 'time': 'PK2Tim_C'},\n",
      "           '3': {'date': 'PKPM0Dat_C', 'time': 'PKPMTim_C'},\n",
      "           '4': {'date': 'PK4Dat_C', 'time': 'PK4Tim_C'},\n",
      "           '5': {'date': 'PK5Dat_C', 'time': 'PK5Tim_C'},\n",
      "           '6': {'date': 'PK6Dat_C', 'time': 'PK6Tim_C'},\n",
      "           '8': {'date': 'PKPM8Dat_C', 'time': 'PKPM8Tim_C'},\n",
      "           '12': {'date': 'PK12Dat_C', 'time': 'PK12Tim_C'},\n",
      "           '16': {'date': 'PK16Dat_C', 'time': 'PK16Tim_C'},\n",
      "           '24': {'date': 'LB24Dat_C', 'time': 'LB24Tim_C'},\n",
      "           '48': {'date': 'PK48Dat_C', 'time': 'PK48Tim_C'},\n",
      "           '72': {'date': 'PK72Dat_C', 'time': 'PK72Tim_C'},\n",
      "           '144': {'date': 'LBEOSDatTScng_C', 'time': 'LBEOSTim_C'}}}\n"
     ]
    }
   ],
   "source": [
    "# [TODO] - Specify the file path to the config file\n",
    "config_filename = './test/pk/config.json'\n",
    "\n",
    "configDict = dict()\n",
    "\n",
    "with open(config_filename) as jsonfile:\n",
    "    configDict = json.load(jsonfile)\n",
    "\n",
    "pprint.pp(configDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Medrio Source File\n",
    "\n",
    "Create dictionary mapping for each subject to allow for hash map search of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] - Specify the file path to the Medrio source file\n",
    "source_filename = './test/pk/source_coh1.csv'\n",
    "\n",
    "# [TODO] - Specify the column header for the subject id details\n",
    "subjectidcol = 'Subject ID'\n",
    "# [TODO] - Specify the column header for the visit details\n",
    "visitCol = 'Visit' # used to find the period\n",
    "\n",
    "# REGULAR EXPRESSION OBJECTS\n",
    "# [TODO] - Specify the regular expression that can identify the date column\n",
    "dateregex = re.compile(r'dat', flags=re.I)\n",
    "\n",
    "# [TODO] - Specify the regular expression that can identify the time column\n",
    "timeregex = re.compile(r'tim', flags=re.I)\n",
    "\n",
    "# [TODO] - Specify the regular expression that can identify the period of the data\n",
    "# Note: Only applicable to certain studies so comment out if not needed (as well as any other occurences of this variable)\n",
    "# Use the regular expression \"capture groups\" to highlight the period number => ([0-9])\n",
    "periodRegex = re.compile(r'period.*([0-9])', flags=re.I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the source file and structure data into the __sourceMap__ dictionary variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICTIONARY FOR SUBJECT DATA\n",
    "sourceMap = dict()\n",
    "\n",
    "# READ THE SOURCE FILE\n",
    "with open(source_filename) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        \n",
    "        # GET THE PERIOD FOR ROW OF DATA\n",
    "        match = periodRegex.search(row.get(visitCol).strip())\n",
    "        if match is None:\n",
    "            print(\"Error: Visit period could not be matched.\")\n",
    "            continue\n",
    "        \n",
    "        # ADD DATA FOR A PARTICULAR SUBJECT ID INTO THE SOURCE MAP DICTIONARY\n",
    "        if row[subjectidcol] not in sourceMap:\n",
    "            sourceMap[f'{row[subjectidcol]}'] = dict()\n",
    "        if match.group(1) not in sourceMap[f'{row[subjectidcol]}']: # NOTE USES REGEX MATCH FOR GROUP TO DETERMINE THE PERIOD NUMBER (1 OR 2 etc.)\n",
    "            sourceMap[f'{row[subjectidcol]}'][f'{match.group(1)}'] = dict()\n",
    "        \n",
    "        # WRITE DATA VALUES TO SOURCE\n",
    "        # CYCLE THROUGH EACH COLUMN IN ROW\n",
    "        for key in row:\n",
    "            if row[key] == '': # EMPTY\n",
    "                continue\n",
    "            value = None\n",
    "            if dateregex.search(key) is not None:\n",
    "                # DATE VARIABLE\n",
    "                value = datetime.datetime.strptime(row.get(key).strip(), '%m/%d/%Y')\n",
    "            elif timeregex.search(key) is not None:\n",
    "                # TIME VARIABLE\n",
    "                value = datetime.datetime.strptime(row.get(key).strip(), '%H:%M')\n",
    "            else:\n",
    "                # INCLUDE EXTRA VARIABLES\n",
    "                value = row.get(key, '')\n",
    "            \n",
    "            sourceMap[f'{row[subjectidcol]}'][f'{match.group(1)}'][f'{key}'] = value # WRITE VALUE TO SOURCE MAP\n",
    "\n",
    "writeFile('source_data_debugging.txt', sourceMap) # OUTPUT MEDRIO DEBUGGING FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Map Dictionary Structure\n",
    "\n",
    "```\n",
    "{\n",
    "    \"subject_id\": {\n",
    "        \"period_id\": {\n",
    "            \"medrio_variable\": {\n",
    "                \"date\": date-object,\n",
    "                \"time\": time-object,\n",
    "                ...\n",
    "             },\n",
    "             ...\n",
    "         },\n",
    "         ...\n",
    "     },\n",
    "     ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Comparison File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] - Specify the file path to the comparison csv file\n",
    "comparisonfilename = './test/pk/comparison_1.csv'\n",
    "\n",
    "# [TODO] - Specify the column header name for the randomisation id column (exact string)\n",
    "randomisationCol = 'Subject'\n",
    "# [TODO] - Specify the column header name for the period identifier column (exact string)\n",
    "periodCol = 'Period'\n",
    "\n",
    "# [TODO] - Specify the regular expression that can identify the period of the data\n",
    "# Note: Only applicable to certain studies so comment out if not needed (as well as any other occurences of this variable)\n",
    "# Use the regular expression \"capture groups\" to highlight the period number => ([0-9])\n",
    "periodRegex = re.compile(r'period.*([0-9])', flags=re.I)\n",
    "\n",
    "# [TODO] - Specify the exact string column header of the input comparison file for the timepoint data point\n",
    "scheduleCol = 'Scheduled time (hrs post dose)'\n",
    "\n",
    "# [TODO] - Specify the exact string column header of the input comparison file for the date data point\n",
    "dateCol = 'Blood Sample date'\n",
    "\n",
    "# [TODO] - Specify the exact string column header of the input comparison file for the time data point\n",
    "timeCol = 'Blood Sample time (24 hrs format)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse comparison file data and structure into the __comparisonMap__ dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICTIONARY OF COMPARISON DATA\n",
    "comparisonMap = dict()\n",
    "\n",
    "# READ THE COMPARISON FILE\n",
    "with open(comparisonfilename) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row[dateCol] == '':\n",
    "            continue # SKIP EMPTY ROWS\n",
    "        \n",
    "        # EXTRACT PERIOD OF DATA\n",
    "        match = periodRegex.search(row.get(periodCol,''))\n",
    "        if match is None:\n",
    "            print(\"Error: Visit period could not be matched.\")\n",
    "            continue\n",
    "        \n",
    "        # CHECK IF DICTIONARY OBJECT STILL NEEDS TO BE CREATED OR ONE HAS ALREADY BEEN CREATED.\n",
    "        if row[randomisationCol] not in comparisonMap:\n",
    "            comparisonMap[f'{row[randomisationCol]}'] = dict()\n",
    "        if match.group(1) not in comparisonMap[f'{row[randomisationCol]}']:\n",
    "            comparisonMap[f'{row[randomisationCol]}'][f'{match.group(1)}'] = dict()\n",
    "        \n",
    "        # GATHER INFORMATION IN ROW BASED ON COLUMN HEADERS\n",
    "        info = {\n",
    "            \"timepoint\": row.get(scheduleCol, ''),\n",
    "            \"date\": datetime.datetime.strptime(row.get(dateCol).strip(), '%d-%b-%y'),\n",
    "            \"time\": datetime.datetime.strptime(row.get(timeCol).strip(), '%H:%M:%S')\n",
    "        }\n",
    "        \n",
    "        # APPEND THE GATHERED INFORMATION TO THE COMPARISON MAP\n",
    "        if info['timepoint'] not in comparisonMap[f'{row[randomisationCol]}'][f'{match.group(1)}']:\n",
    "            comparisonMap[f'{row[randomisationCol]}'][f'{match.group(1)}'][f'{info[\"timepoint\"]}'] = info\n",
    "        elif comparisonMap[f'{row[randomisationCol]}'][f'{match.group(1)}'][f'{info[\"timepoint\"]}']['date'] != info['date']:\n",
    "            # the date in script does not match previously recorded dates\n",
    "            raise Exception(\"ERROR: date for data point is not consistent within file!\")\n",
    "        elif comparisonMap[f'{row[randomisationCol]}'][f'{match.group(1)}'][f'{info[\"timepoint\"]}']['time'] != info['time']:\n",
    "            # the date in script does not match previously recorded dates\n",
    "            raise Exception(\"ERROR: time for data point is not consistent within file!\")\n",
    "\n",
    "writeFile('comparisonData.txt', comparisonMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Map Dictionary Structure\n",
    "\n",
    "```\n",
    "{\n",
    "    \"randomisation_number\": {\n",
    "        \"period_id\": {\n",
    "            \"timepoint\": {\n",
    "                \"date\": date-object\n",
    "                \"time\": time-object\n",
    "             },\n",
    "             ...\n",
    "         },\n",
    "         ...\n",
    "     },\n",
    "     ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Data & Assess Equality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare matching data points and flag inequalities. This block of code will only flag errors, hence assume date and time's are consistent if there is nothing to report in the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV write complete.\n"
     ]
    }
   ],
   "source": [
    "outputLog = {\"errors\": 0, \"total\": 0} # Keep track of errors so that an error log can be printed / written to file\n",
    "\n",
    "# CYCLE THROUGH EACH RANDOMISATION NUMBER IN THE COMPARISON MAP\n",
    "for subject in comparisonMap:\n",
    "    outputLog[f'{subject}'] = list() # STATUS REPORTING\n",
    "\n",
    "    # FIND THE SUBJECT ID FOR THE RANDOMISATION NUMBER\n",
    "    id = subjectMap.get(subject, None) # medrio subject id\n",
    "    if id is None: # SUBJECT ID NOT DEFINED\n",
    "        outputLog[f'{subject}'].append({\n",
    "            \"status\": \"FAILED\",\n",
    "            \"msg\": \"Medrio subject id could not be identified.\"\n",
    "        })\n",
    "        outputLog['errors'] += 1\n",
    "        continue # GO TO NEXT RANDOMISATION NUMBER\n",
    "    \n",
    "    # COMPARE DATA AND LOG ANY ERRORS\n",
    "    # CYCLE THROUGH EACH PERIOD IN THE STUDY\n",
    "    for period in comparisonMap[subject]:\n",
    "        # CYCLE THROUGH EACH COLLECTION TIMEPOINT\n",
    "        for timepoint in comparisonMap[subject][period]:\n",
    "            \n",
    "            lookuptable = configDict['match'][timepoint] # TIMEPOINT LOOKUP TABLE DEFINED IN THE CONFIG FILE\n",
    "            \n",
    "            errorObject = dict()\n",
    "            \n",
    "            # CYCLE THROUGH THE DATE AND TIME VARIABLES THAT NEED TO BE COMPARED\n",
    "            try:\n",
    "                datecmp = sourceMap[f'{id}'][period][f'{lookuptable[\"date\"]}'].date() == comparisonMap[subject][period][timepoint]['date'].date() # COMPARE DATES\n",
    "                timecmp = sourceMap[f'{id}'][period][f'{lookuptable[\"time\"]}'].time() == comparisonMap[subject][period][timepoint]['time'].time() # COMPARE TIMES\n",
    "            except KeyError as e:\n",
    "                errorObject = {\n",
    "                    \"error\": True,\n",
    "                    'msg': \"Warning: variable most likely not defined for subject in source.\",\n",
    "                }\n",
    "            except:\n",
    "                print('Unknown Error Occured.')\n",
    "                errorObject = {\n",
    "                    \"error\": True,\n",
    "                    'msg': \"Unknown error occured\",\n",
    "                }\n",
    "            \n",
    "            dateError = {'error': False}\n",
    "            timeError = {'error': False}\n",
    "            outputLog['total'] += 1 # increment number of variables assessed\n",
    "            \n",
    "            if not datecmp: # ERROR WITH DATE COMPARISON\n",
    "                dateError = {\n",
    "                        \"variable\": lookuptable['date'],\n",
    "                        \"source\": sourceMap[f'{id}'][period][f'{lookuptable[\"date\"]}'].date().isoformat(),\n",
    "                        \"pk\": comparisonMap[subject][period][timepoint]['date'].date().isoformat(),\n",
    "                        \"error\": True\n",
    "                    }\n",
    "            if not timecmp: # ERROR WITH TIME COMPARISON\n",
    "                timeError = {\n",
    "                        \"variable\": lookuptable['time'],\n",
    "                        \"source\": sourceMap[f'{id}'][period][f'{lookuptable[\"time\"]}'].time().isoformat(),\n",
    "                        \"pk\": comparisonMap[subject][period][timepoint]['time'].time().isoformat(),\n",
    "                        \"error\": True\n",
    "                    }\n",
    "            # APPEND ACCUMULATED ERRORS TO THE ERROR LOG\n",
    "            if not datecmp or not timecmp or errorObject.get('error', False):\n",
    "                outputLog['errors'] += 1\n",
    "                outputLog[f'{subject}'].append({\n",
    "                    **errorObject, \n",
    "                    'period': f'Period {period}',\n",
    "                    'timepoint': timepoint,\n",
    "                    'subjectid': id,\n",
    "                    'date': dateError,\n",
    "                    'time': timeError,\n",
    "                })\n",
    "\n",
    "            \n",
    "writeJSON('output.json', outputLog)\n",
    "writeFile('output.txt', outputLog)\n",
    "writeErrorCSV('output.csv', outputLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.patches.Wedge at 0x111b3eac0>,\n",
       "  <matplotlib.patches.Wedge at 0x111b3ef70>],\n",
       " [Text(1.0922792053850408, 0.13010048994306012, '8'),\n",
       "  Text(-1.092279193204149, -0.13010059220961942, '204')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.pie([outputLog['errors'], outputLog['total']], labels=[outputLog['errors'], outputLog['total']], colors=['#f42613', '#47f747'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
